{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import json\n",
    "from pathlib import Path\n",
    "from pprint import pprint\n",
    "import numpy as np\n",
    "\n",
    "import configparser\n",
    "\n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns\n",
    "\n",
    "from tqdm._tqdm_notebook import tqdm_notebook as tqdm\n",
    "tqdm.pandas()\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "from _helpers import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/asura/.virtualenvs/altmetrics/lib/python3.5/site-packages/numpy/lib/arraysetops.py:463: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  mask |= (ar1 == a)\n"
     ]
    }
   ],
   "source": [
    "# Load config\n",
    "root = Path('../../')\n",
    "Config = configparser.ConfigParser()\n",
    "Config.read(str(root / 'config.cnf'))\n",
    "\n",
    "queries = root / Config.get('input_files', 'queries')\n",
    "queries = load_queries(str(queries))\n",
    "\n",
    "tweets = root / Config.get('output_files', 'tweets')\n",
    "twitter_urls = root / Config.get('output_files', 'twitter_urls')\n",
    "altmetric_urls = root / Config.get('output_files',  'altmetric_urls')\n",
    "\n",
    "twitter_urls = load_urls(twitter_urls)\n",
    "altmetric_urls = load_altmetric(altmetric_urls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = altmetric_urls[(altmetric_urls['clean_url'].notnull()) & (altmetric_urls.relevant == True)]\n",
    "am_urls_per_source = df.groupby(\"venue_short\")['clean_url'].apply(lambda x: set(x.unique()))\n",
    "\n",
    "df = twitter_urls[(twitter_urls['cleaned_url'].notnull()) & (twitter_urls.relevant == True)]\n",
    "tw_urls_per_source = df.groupby(\"venue\")['cleaned_url'].apply(lambda x: set(x.unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Twitter</th>\n",
       "      <th>Altmetric</th>\n",
       "      <th>both</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>slate</th>\n",
       "      <td>219</td>\n",
       "      <td>53</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wired</th>\n",
       "      <td>255</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bostonglobe</th>\n",
       "      <td>226</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sfchronicle</th>\n",
       "      <td>325</td>\n",
       "      <td>19</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>latimes</th>\n",
       "      <td>2065</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>theglobeandmail</th>\n",
       "      <td>176</td>\n",
       "      <td>24</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>foxnews</th>\n",
       "      <td>3474</td>\n",
       "      <td>253</td>\n",
       "      <td>231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>washingtonpost</th>\n",
       "      <td>4617</td>\n",
       "      <td>593</td>\n",
       "      <td>315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nytimes</th>\n",
       "      <td>4528</td>\n",
       "      <td>342</td>\n",
       "      <td>318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>theguardian</th>\n",
       "      <td>2113</td>\n",
       "      <td>591</td>\n",
       "      <td>542</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Twitter Altmetric both\n",
       "slate               219        53    1\n",
       "wired               255         1    1\n",
       "bostonglobe         226         4    3\n",
       "sfchronicle         325        19    5\n",
       "latimes            2065        10   10\n",
       "theglobeandmail     176        24   23\n",
       "foxnews            3474       253  231\n",
       "washingtonpost     4617       593  315\n",
       "nytimes            4528       342  318\n",
       "theguardian        2113       591  542"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(columns=['Twitter', 'Altmetric', 'both'])\n",
    "for ix, tw_urls in tw_urls_per_source.iteritems():\n",
    "    try:\n",
    "        tw = len(tw_urls)\n",
    "        if ix in am_urls_per_source:\n",
    "            am_urls = am_urls_per_source[ix]\n",
    "            am = len(am_urls)\n",
    "            both = len(tw_urls.intersection(am_urls))\n",
    "        else:\n",
    "            am = 0\n",
    "            both = 0\n",
    "        df.loc[ix] = [tw, am, both]\n",
    "    except:\n",
    "        raise\n",
    "df.sort_values(by=\"both\")\n",
    "# df.index.name = \"venue\"\n",
    "# df.to_csv(\"results.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
